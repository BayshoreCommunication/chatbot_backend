# Deployment Disk Space Fix

## Problem
GitHub Actions deployment was failing with:
```
Reload daemon failed: Refusing to reload, not enough space available on /run/systemd/. 
Currently, 3.6M are free, but a safety buffer of 16M is enforced.
Process exited with status 1
```

## Root Cause
1. **Server disk full** - `/run/systemd/` only had 3.6M free space but needs 16M minimum
2. **Docker daemon reload failing** - `systemctl enable docker` triggers daemon reload which requires disk space
3. **Log files and Docker cache** consuming too much space

## Solution

### 1. Enhanced Emergency Disk Cleanup
Added aggressive cleanup of systemd runtime directories:

```yaml
# Clean systemd runtime directories
sudo journalctl --vacuum-time=1h
sudo journalctl --vacuum-size=10M
sudo rm -rf /run/log/journal/*
sudo rm -rf /var/log/journal/*

# Clean /run/systemd/ specifically
sudo find /run/systemd/ -type f -name "*.timer" -delete
sudo find /run/systemd/ -type f -name "*.service" -delete
sudo rm -rf /run/systemd/transient/*
sudo rm -rf /run/systemd/units/*
```

### 2. Avoid Daemon Reload
Changed Docker service handling to avoid triggering daemon reload:

**Before (CAUSES ERROR):**
```yaml
sudo systemctl start docker
sudo systemctl enable docker  # ‚Üê This triggers daemon reload
```

**After (SAFE):**
```yaml
# Only start Docker if not running
if ! sudo systemctl is-active --quiet docker; then
  sudo systemctl start docker
fi
# Skip enable to avoid daemon reload
```

### 3. Stop Docker Before Cleanup
Added proper Docker stop before cleanup:

```yaml
# Stop Docker first (don't reload daemon yet)
sudo systemctl stop docker
# Then clean up Docker files...
```

### 4. Better Error Recovery
Added restart fallback if Docker fails to start:

```yaml
timeout 30 bash -c 'until docker info >/dev/null 2>&1; do sleep 1; done' || {
  echo "‚ùå Docker failed to start, trying restart..."
  sudo systemctl restart docker
  sleep 5
  docker info || exit 1
}
```

## Changes Made

### File: `.github/workflows/deploy.yml`

#### 1. Emergency Disk Cleanup Step (Lines ~50-115)
- Added `/run/systemd/` specific cleanup
- Added systemd journal cleanup
- Stop Docker before cleanup
- Start Docker without daemon reload

#### 2. Docker Service Start (Lines ~250-270)
- Check if Docker is already running
- Only start if needed
- Skip `systemctl enable` to avoid daemon reload
- Added restart fallback

#### 3. Enhanced Monitoring
- Show `/run/systemd/` disk usage
- Display largest files in `/run/systemd/`
- Better error messages

## Disk Space Cleanup Targets

The deployment now cleans:

1. **Docker:**
   - All stopped containers
   - All images
   - All volumes
   - Build cache
   - Overlay2 storage

2. **System Logs:**
   - Journal logs (keep only 1 hour)
   - System logs older than 7 days
   - `/run/log/journal/*`
   - `/var/log/journal/*`

3. **Systemd Runtime:**
   - Timer files
   - Service files
   - Transient units
   - Cached units

4. **Package Manager:**
   - APT cache
   - Old kernels
   - Unused packages

5. **Temporary Files:**
   - `/tmp/*`
   - `/var/tmp/*`
   - `~/.cache/*`
   - `~/.npm/*`

## Expected Behavior

### Before Fix:
```
üê≥ Starting Docker service...
Reload daemon failed: Refusing to reload, not enough space available on /run/systemd/
Error: Process completed with exit code 1
```

### After Fix:
```
üßπ Cleaning systemd runtime...
üìä Space in /run/systemd/: 45M available
üê≥ Starting Docker service...
‚úÖ Docker is running
üöÄ Building and deploying application...
‚úÖ Deployment successful
```

## Testing

### 1. Check Disk Space
```bash
ssh user@server
df -h
df -h /run/systemd/
```

### 2. Check Docker Status
```bash
sudo systemctl status docker
docker info
```

### 3. Monitor Deployment
Watch GitHub Actions logs for:
- ‚úÖ Emergency cleanup completes
- ‚úÖ `/run/systemd/` has enough space
- ‚úÖ Docker starts without errors
- ‚úÖ Application deploys successfully

## Prevention

To prevent future disk space issues:

1. **Regular Cleanup:**
   - Add cron job to clean Docker weekly
   - Rotate logs more aggressively
   - Monitor disk usage

2. **Docker Limits:**
   ```bash
   # Add to /etc/docker/daemon.json
   {
     "log-driver": "json-file",
     "log-opts": {
       "max-size": "10m",
       "max-file": "3"
     }
   }
   ```

3. **System Settings:**
   ```bash
   # Limit journal size
   sudo journalctl --vacuum-size=100M
   sudo journalctl --vacuum-time=7d
   ```

## Manual Server Cleanup (If Needed)

If deployment still fails, SSH to server and run:

```bash
# Stop Docker
sudo systemctl stop docker

# Clean Docker completely
sudo docker system prune -af --volumes
sudo rm -rf /var/lib/docker/tmp/*
sudo rm -rf /var/lib/docker/overlay2/*

# Clean systemd
sudo journalctl --vacuum-size=10M
sudo rm -rf /run/systemd/transient/*

# Clean logs
sudo rm -rf /var/log/*.gz
sudo rm -rf /tmp/*

# Restart Docker
sudo systemctl start docker

# Check space
df -h
```

## Status
‚úÖ **FIXED** - Deployment now handles low disk space gracefully

## Files Modified
- `.github/workflows/deploy.yml` - Enhanced cleanup and Docker service handling
- `DEPLOYMENT_DISK_SPACE_FIX.md` - This documentation
